{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import whisper\n",
    "from whisper.transcribe import transcribe\n",
    "from whisper.audio import SAMPLE_RATE\n",
    "\n",
    "\n",
    "model = whisper.load_model('large-v1')\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "model.encoder.to(device)\n",
    "model.decoder.to(device)\n",
    "model.decoder.register_forward_pre_hook(lambda _, inputs: tuple([inputs[0].to(device), inputs[1].to(device)] + list(inputs[2:])))\n",
    "model.decoder.register_forward_hook(lambda _, inputs, outputs: outputs.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torchaudio\n",
    "import IPython.display as ipd\n",
    "\n",
    "audio_path = Path('/home/server2/librivox/Stephan/island_dr_moreau_08_wells.mp3')\n",
    "audio, sr = torchaudio.load(audio_path)\n",
    "audio = audio[0, sr*20:sr*45]\n",
    "if sr != SAMPLE_RATE:\n",
    "    audio = torchaudio.functional.resample(audio, orig_freq=sr, new_freq=SAMPLE_RATE)\n",
    "    \n",
    "out = transcribe(model, audio, verbose=True, language='en')\n",
    "ipd.display(ipd.Audio(data=audio, rate=SAMPLE_RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_ds_folder = Path('~/datasets/Stephan').expanduser()\n",
    "out_ds_wav_folder = out_ds_folder / 'wavs'\n",
    "out_ds_wav_folder.mkdir(exist_ok=True)\n",
    "out_ds_filelsit = out_ds_folder / 'meta.txt'\n",
    "\n",
    "audio_folder = audio_path.parent\n",
    "\n",
    "target_sr = 22050\n",
    "audio_paths = [audio_path for audio_path in audio_folder.iterdir() if audio_path.suffix == '.mp3']\n",
    "audio_paths.sort()\n",
    "\n",
    "duration = 0\n",
    "for audio_path in audio_paths:\n",
    "    audio, sr = torchaudio.load(audio_path)\n",
    "    duration += audio.shape[-1] / sr\n",
    "    print(str(audio_path))\n",
    "print(f'Duration: {duration / (60 * 60):.2f} hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "meta = []\n",
    "\n",
    "for audio_idx, audio_path in enumerate(tqdm(audio_paths)):\n",
    "    audio, sr = torchaudio.load(audio_path)\n",
    "    audio = audio[0, :]\n",
    "    if sr != SAMPLE_RATE:\n",
    "        audio = torchaudio.functional.resample(audio, orig_freq=sr, new_freq=SAMPLE_RATE)\n",
    "    out = transcribe(model, audio, verbose=True, language='en')\n",
    "\n",
    "    audio, sr = torchaudio.load(audio_path)\n",
    "    audio = audio[0, :]\n",
    "    if sr != target_sr:\n",
    "        audio = torchaudio.functional.resample(audio, orig_freq=sr, new_freq=target_sr)\n",
    "\n",
    "    for s_idx, segment in enumerate(out['segments']):\n",
    "        start_idx = math.floor(target_sr * segment['start'])\n",
    "        end_idx = math.ceil(target_sr * segment['end'])\n",
    "        wav = audio[start_idx:end_idx]\n",
    "        wav_path = out_ds_wav_folder / f'{audio_idx}_{s_idx}.wav'\n",
    "        torchaudio.save(filepath=wav_path, src=wav.unsqueeze(0), sample_rate=target_sr)\n",
    "        meta.append((wav_path, segment['text'], 'stephan'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import IPython.display as ipd\n",
    "\n",
    "r_idx = random.randint(0, len(meta) - 1)\n",
    "\n",
    "wav_path, text, speaker = meta[r_idx]\n",
    "\n",
    "print(text)\n",
    "ipd.display(ipd.Audio(filename=wav_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(out_ds_filelsit, 'w') as file:\n",
    "    for wav_path, text, speaker in meta:\n",
    "        wav_path = Path(wav_path)\n",
    "        text = text.strip()\n",
    "        rel_wav_path = wav_path.relative_to(out_ds_folder)\n",
    "        file.write(f'{str(rel_wav_path)}|{text}|{speaker}\\n')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
